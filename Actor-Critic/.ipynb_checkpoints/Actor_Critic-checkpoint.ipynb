{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "oq2uBLgkNY09"
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import haiku as hk\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.nn as nn\n",
    "import jax.random as random\n",
    "import numpy as np\n",
    "import optax\n",
    "import matplotlib.pyplot as plt\n",
    "from jax import tree_map\n",
    "from jax import grad, vjp, value_and_grad\n",
    "from jax import lax\n",
    "from jax import jit\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "HjX9aTaFQa0x"
   },
   "outputs": [],
   "source": [
    "def policy_fn(observation):\n",
    "  mlp = hk.Sequential(\n",
    "      [\n",
    "       hk.Linear(20), nn.relu,\n",
    "       hk.Linear(2)\n",
    "      ]\n",
    "  )\n",
    "  return mlp(observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Mnlj4GQQYZmG"
   },
   "outputs": [],
   "source": [
    "\n",
    "def val_fn(observation):\n",
    "  mlp = hk.Sequential(\n",
    "      [\n",
    "       hk.Linear(64), nn.relu,\n",
    "       hk.Linear(1)\n",
    "      ]\n",
    "  )\n",
    "  return mlp(observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "UOYKj9PgHC2c"
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "  NUM_EPISODE = 2000\n",
    "  GAMMA = 0.95\n",
    "  BATCH = 2\n",
    "  RECORD_INTERVAL = 20\n",
    "  ANNEAL_SCHEDULE = 100\n",
    "\n",
    "  rng = hk.PRNGSequence(0)\n",
    "\n",
    "  actor = hk.without_apply_rng(hk.transform(policy_fn))\n",
    "  critic = hk.without_apply_rng(hk.transform(val_fn))\n",
    "\n",
    "  dummy_obs = jnp.array([0,0,0,0],dtype=jnp.float32)\n",
    "\n",
    "  actor_params = actor.init(rng.next(), dummy_obs)\n",
    "  critic_params = critic.init(rng.next(), dummy_obs)\n",
    "\n",
    "\n",
    "  actor_opt = optax.adam(1e-4)\n",
    "  critic_opt = optax.adam(1e-3)\n",
    "\n",
    "  actor_opt_state = actor_opt.init(actor_params)\n",
    "  critic_opt_state = critic_opt.init(critic_params)\n",
    "\n",
    "\n",
    "  @jit\n",
    "  def actor_obj(params, obs, rand):\n",
    "    logits = actor.apply(params, obs)\n",
    "    action = lax.stop_gradient(random.categorical(rand,logits))\n",
    "    return nn.log_softmax(logits)[action], action \n",
    "  \n",
    "  @jit\n",
    "  def update_actor(params, opt_state, gradient):\n",
    "    updates, new_opt_state = actor_opt.update(gradient, opt_state)\n",
    "    new_params = optax.apply_updates(params, updates)\n",
    "    return new_params, new_opt_state\n",
    "  \n",
    "#   @jit\n",
    "#   def update_actor(params, gradient, lr):\n",
    "#     params = tree_map(lambda p, g: p + lr*g, params, gradient)\n",
    "#     return params\n",
    "  \n",
    "  @jit\n",
    "  def accumulate_actor_grad(cum_grad, log_grad, tde, discount):\n",
    "    new_cum_grad = tree_map(lambda cg, lg: cg + discount*tde*lg, cum_grad, log_grad)\n",
    "    return new_cum_grad\n",
    "  \n",
    "  @jit\n",
    "  def zero_tree(tree):\n",
    "    return tree_map(lambda x: 0*x, tree)\n",
    "  \n",
    "  \n",
    "  \n",
    "  \n",
    "  @jit\n",
    "  def critic_obj(params, obs, reward, next_obs, gamma):\n",
    "    v_t = critic.apply(params, obs)\n",
    "    target = reward + gamma*critic.apply(params, next_obs)\n",
    "    td_error = lax.stop_gradient(target) - v_t\n",
    "    return (td_error**2)[0], td_error\n",
    "  @jit\n",
    "  def update_critic(params, opt_state, gradient):\n",
    "    updates, new_opt_state = critic_opt.update(gradient, opt_state)\n",
    "    new_params = optax.apply_updates(params, updates)\n",
    "    return new_params, new_opt_state\n",
    "\n",
    "  \n",
    "  env = gym.make('CartPole-v0')\n",
    "  env.seed(1)\n",
    "  episode_lengths = []\n",
    "  avg_tde = []\n",
    "  lr = 1e-6\n",
    "\n",
    "  for eps in tqdm(range(NUM_EPISODE)):\n",
    "    # initialization for each episode\n",
    "    o_t = jnp.array(env.reset(), dtype=jnp.float32)\n",
    "    done = False\n",
    "    I = 1.0\n",
    "    cumulative_tde = 0\n",
    "    num_step = 0\n",
    "    cum_actor_grad = zero_tree(actor_params)\n",
    "    \n",
    "    # learning rate annealing\n",
    "    if eps % ANNEAL_SCHEDULE == 0:\n",
    "      lr = lr/2\n",
    "    \n",
    "    while not done:\n",
    "      likelihood_grad, action = grad(actor_obj, has_aux=True)(actor_params, o_t, rng.next())\n",
    "      env.render()\n",
    "\n",
    "      num_step += 1\n",
    "\n",
    "      o_tp1, reward, done, _ = env.step(action.item())\n",
    "      o_tp1 = jnp.array(o_tp1, dtype=jnp.float32)\n",
    "\n",
    "      critic_grad, tde = grad(critic_obj,has_aux=True)(critic_params, o_t, reward, o_tp1,GAMMA)\n",
    "      cumulative_tde += abs(tde.item())\n",
    "      critic_params, critic_opt_state = update_critic(critic_params, critic_opt_state, critic_grad)\n",
    "      \n",
    "      cum_actor_grad = accumulate_actor_grad(cum_actor_grad, likelihood_grad, tde.item(), I)\n",
    "      if num_step % BATCH == 0:\n",
    "        actor_params, actor_opt_state = update_actor(actor_params, actor_opt_state, cum_actor_grad)\n",
    "        cum_actor_grad = zero_tree(cum_actor_grad)\n",
    "\n",
    "      I = GAMMA*I\n",
    "      o_t = o_tp1\n",
    "\n",
    "    actor_params, actor_opt_state = update_actor(actor_params, actor_opt_state,cum_actor_grad)\n",
    "    \n",
    "    if eps % RECORD_INTERVAL == 0:\n",
    "      episode_lengths.append(num_step)\n",
    "      avg_tde.append(cumulative_tde/num_step)\n",
    "    \n",
    "  plt.figure()\n",
    "  plt.plot(episode_lengths,'b')\n",
    "  plt.xlabel('episode')\n",
    "  plt.ylabel('length')\n",
    "\n",
    "  plt.figure()\n",
    "  plt.plot(avg_tde,'r')\n",
    "  plt.xlabel('episode')\n",
    "  plt.ylabel('TD-error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|█▎                                       | 65/2000 [00:27<15:19,  2.10it/s]"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Actor-Critic.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
